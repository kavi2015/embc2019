{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EMBC2019_probmap_resnet18_rf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "wiahzM1EfnfQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Mounting Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "Ci2gPZb6ZIEw",
        "colab_type": "code",
        "outputId": "3c863126-8215-44a8-a1f8-58c89f96f1fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "##### Importing data via Google Drive mount\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z3N68kUFfu1I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Loading Train, Val, and Test Data Using Keras ImageDataGenerator"
      ]
    },
    {
      "metadata": {
        "id": "oeCnbRQ-ZVQO",
        "colab_type": "code",
        "outputId": "52e20306-add3-4374-b5f4-4a6fa8aaafb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Directory Paths\n",
        "train_dir = \"/gdrive/My Drive/newCircleData/Train/\"\n",
        "val_dir = \"/gdrive/My Drive/newCircleData/Val/\"\n",
        "test_dir = \"/gdrive/My Drive/newCircleData/Test/\"\n",
        "\n",
        "#Image dims and training details\n",
        "img_width = 600\n",
        "img_height = 450\n",
        "batch_size = 1\n",
        "channels = 3\n",
        "epochs = 50\n",
        "nb_train_samples = 395\n",
        "nb_valid_samples = 145\n",
        "nb_test_samples = 197\n",
        "\n",
        "#Keras ImageDataGenerator for loading train, val, and test data\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)             \n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)    \n",
        "test_datagen = ImageDataGenerator(rescale=1./255) \n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, \n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True)   \n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True) #weight toward one class or another\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 395 images belonging to 2 classes.\n",
            "Found 145 images belonging to 2 classes.\n",
            "Found 197 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8DSNcgHwfzN2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Building the Model Architecture (Pre-trained ResNet-18 Extracting Features from OCT Dataset) & Training the Model"
      ]
    },
    {
      "metadata": {
        "id": "EQ2UeGrosA4d",
        "colab_type": "code",
        "outputId": "823a5892-6ef2-452f-9f45-0cbbbede81bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "cell_type": "code",
      "source": [
        "# Download the ResNet18 model\n",
        "\n",
        "!git clone https://github.com/qubvel/classification_models.git\n",
        "  \n",
        "from classification_models.classification_models.resnet import models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'classification_models' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-5V7skIXZQrr",
        "colab_type": "code",
        "outputId": "9490b0d1-9e50-4462-ba01-0b66049f182a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#Loading Pretrained ResNet Model and Extracting Features\n",
        "import numpy as np \n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Softmax, Flatten, Dense, BatchNormalization \n",
        "from keras.metrics import categorical_accuracy\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras import layers\n",
        "\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "#from keras.layers import Input, Dense\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras.applications import ResNet50#, VGG16\n",
        "\n",
        "# from classfication_models import classfication_models\n",
        "\n",
        "conv_base = models.ResNet18(include_top=False, input_shape=(img_height, img_width, channels), weights='imagenet', classes=2)\n",
        "\n",
        "# conv_base = ResNet50(include_top=False, weights='imagenet',input_shape=(img_height, img_width, channels), pooling=None)\n",
        "\n",
        "\n",
        "# For VGG16\n",
        "# model_1st = 14\n",
        "# model_2nd = 18\n",
        "# model_3rd = 512\n",
        "\n",
        "# For ResNet50\n",
        "# model_1st = 15\n",
        "# model_2nd = 19\n",
        "# model_3rd = 2048\n",
        "\n",
        "# For ResNet18\n",
        "model_1st = 15\n",
        "model_2nd = 19\n",
        "model_3rd = 512\n",
        "\n",
        "#Extracting features from OCT data using pretrained VGG\n",
        "def extract_features(dataset_type, sample_count):\n",
        "    features = np.zeros(shape=(sample_count, model_1st, model_2nd, model_3rd))\n",
        "    labels = np.zeros(shape=(sample_count))\n",
        "    i = 0\n",
        "    if dataset_type == \"train\":\n",
        "        for inputs_batch, labels_batch in train_generator:\n",
        "            features_batch = conv_base.predict(inputs_batch)\n",
        "            features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "            labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "            i += 1\n",
        "            if i * batch_size >= sample_count:\n",
        "                break   \n",
        "    elif dataset_type == \"valid\":\n",
        "        for inputs_batch, labels_batch in valid_generator:\n",
        "            features_batch = conv_base.predict(inputs_batch)\n",
        "            features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "            labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "            i += 1\n",
        "            if i * batch_size >= sample_count:\n",
        "                break\n",
        "    else:\n",
        "        for inputs_batch, labels_batch in test_generator:\n",
        "            features_batch = conv_base.predict(inputs_batch)\n",
        "            features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "            labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "            i += 1\n",
        "            if i * batch_size >= sample_count:\n",
        "                break\n",
        "    return features, labels\n",
        "\n",
        "train_features, train_labels = extract_features(\"train\", nb_train_samples)\n",
        "valid_features, valid_labels = extract_features(\"valid\", nb_valid_samples)\n",
        "test_features, test_labels = extract_features(\"test\", nb_test_samples)\n",
        "\n",
        "\n",
        "print(train_features.shape, train_labels.shape)\n",
        "print(valid_features.shape, valid_labels.shape)\n",
        "print(test_features.shape, test_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(394, 15, 19, 512) (394,)\n",
            "(145, 15, 19, 512) (145,)\n",
            "(197, 15, 19, 512) (197,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hdgxyp8mgBI2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classifier Layer: Random Forest"
      ]
    },
    {
      "metadata": {
        "id": "pC1hJV8fsTGE",
        "colab_type": "code",
        "outputId": "615eb351-ca08-48ed-d059-303b422ae3d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "cell_type": "code",
      "source": [
        "#Using SkLearn Random Forest for training, validation, and testing of OCT features\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=12, random_state=0, bootstrap=True)\n",
        "clf.fit(np.reshape(train_features, (nb_train_samples, model_2nd*model_1st*model_3rd)), train_labels)\n",
        "\n",
        "prediction = clf.predict(np.reshape(valid_features, (nb_valid_samples, model_2nd*model_1st*model_3rd)))\n",
        "print(\"validation accuracy:\", sum([prediction[i] == valid_labels[i] for i in range(len(valid_labels))])/len(valid_labels))\n",
        "\n",
        "prediction = clf.predict(np.reshape(test_features, (nb_test_samples, model_2nd*model_1st*model_3rd)))\n",
        "print(\"test accuracy:\", sum([prediction[i] == test_labels[i] for i in range(len(test_labels))])/len(test_labels))\n",
        "\n",
        "print(test_labels)\n",
        "print(prediction)\n",
        "\n",
        "print('ROC AUC is', roc_auc_score(test_labels, prediction, 'weighted'))\n",
        "\n",
        "#Getting false positives and false negatives\n",
        "\n",
        "print([i for i in range(len(test_labels)) if prediction[i] != test_labels[i]])\n",
        "\n",
        "filenames = test_generator.filenames   \n",
        "FP_list = []\n",
        "FN_list = []\n",
        "\n",
        "#FP\n",
        "for i in range(len(test_labels)):\n",
        "  if test_labels[i] == 0 and prediction[i] == 1:\n",
        "    FP_list.append(filenames[i])\n",
        "\n",
        "#FN\n",
        "for i in range(len(test_labels)):\n",
        "  if test_labels[i] == 1 and prediction[i] == 0:\n",
        "    FN_list.append(filenames[i])\n",
        "    \n",
        "print(FP_list)\n",
        "print(FN_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validation accuracy: 0.9586206896551724\n",
            "test accuracy: 0.949238578680203\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1.]\n",
            "ROC AUC is 0.9480793854033289\n",
            "[0, 10, 35, 55, 68, 83, 89, 90, 96, 162]\n",
            "['G/19160_RNFL_probability.png', 'G/20163_RNFL_probability.png', 'G/26768_RNFL_probability.png']\n",
            "['S/19088_RNFL_probability.png', 'S/22103_RNFL_probability.png', 'S/27449_RNFL_probability.png', 'S/30168_RNFL_probability.png', 'S/30455_RNFL_probability.png', 'S/31801_RNFL_probability.png', 'S/View2163.png']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
